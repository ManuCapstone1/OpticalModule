{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code first uses three corners on one image to apply affine transformation, then uses another image to validate the results and caculate errors. Corner coordinates are obtained manually."
      ],
      "metadata": {
        "id": "nBSPqHqFtuLQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HrmOeTXmMVa",
        "outputId": "b1f30c90-a284-4072-bfd8-bfdeba707c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Affine Transformation Matrix:\n",
            "[[719.  24. 284.]\n",
            " [-16. 713. 108.]]\n",
            "\n",
            "Transformed Camera Coordinates:\n",
            "[[1099. 2944.]\n",
            " [3975. 2880.]\n",
            " [1003.   92.]]\n",
            "\n",
            "Error Offset:\n",
            "[[79.  0.]\n",
            " [75. 38.]\n",
            " [59. 36.]]\n",
            "\n",
            "Error in Stage Units (mm):\n",
            "[[0.10981367 0.        ]\n",
            " [0.10425348 0.05328252]\n",
            " [0.08201274 0.05047818]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Define original stage points (source),\n",
        "stage_pts = np.float32([[0,4], [44], [0,0]])\n",
        "\n",
        "camera_pts =  np.float32([[380, 2960], [3256, 2896], [284, 108]])\n",
        "\n",
        "# Compute affine transformation matrix\n",
        "T = cv2.getAffineTransform(stage_pts, camera_pts)\n",
        "\n",
        "# Print the transformation matrix\n",
        "print(\"Affine Transformation Matrix:\")\n",
        "print(T)\n",
        "\n",
        "# Transform new stage points (from image 2)\n",
        "new_stage_pts = np.float32([[1,4], [5,4], [1,0]])  # Points from image 2 (stage)\n",
        "\n",
        "# Convert points using the affine transformation\n",
        "new_camera_pts = cv2.transform(np.array([new_stage_pts]), T)\n",
        "\n",
        "# Display transformed points\n",
        "print(\"\\nTransformed Camera Coordinates:\")\n",
        "print(new_camera_pts[0])\n",
        "\n",
        "# Calculate error offset\n",
        "# For simplicity, we calculate the error as the difference between transformed points and expected points.\n",
        "\n",
        "# Assuming the expected camera points (ground truth for new stage points)\n",
        "expected_camera_pts = np.float32([[1020, 2944], [3900, 2842], [944, 56]])  # Expected points\n",
        "\n",
        "# Calculate the error (difference) between transformed points and expected points\n",
        "error = new_camera_pts[0] - expected_camera_pts\n",
        "print(\"\\nError Offset:\")\n",
        "print(error)\n",
        "\n",
        "# Extract scaling factors from the affine transformation matrix (T)\n",
        "# The scaling factors are in the first two elements of the matrix rows\n",
        "scale_x = np.linalg.norm(T[0, :2])  # X scaling (magnitude of the first row)\n",
        "scale_y = np.linalg.norm(T[1, :2])  # Y scaling (magnitude of the second row)\n",
        "\n",
        "# Scale the error back to stage units\n",
        "error_in_stage_units = error / np.array([scale_x, scale_y])\n",
        "\n",
        "print(\"\\nError in Stage Units (mm):\")\n",
        "print(error_in_stage_units)"
      ]
    }
  ]
}