{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is an automatic method of establishing scaling and rotation aspects of affine transformation. However, because the code is looking for random features on the images, it is hard to consistently get the same absolute zero every time"
      ],
      "metadata": {
        "id": "1grscDSHsxxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load images\n",
        "img1 = cv2.imread('/content/sample1_(59.0051385,155.99516625,80.0)_20250314_192822.jpg')\n",
        "img2 = cv2.imread('/content/sample1_(59.0051385,157.00244175,80.0)_20250314_192738.jpg')\n",
        "img3 = cv2.imread('/content/sample1_(59.999160375,157.00244175,80.0)_20250314_192536.jpg')\n",
        "\n",
        "# Convert to grayscale for feature detection\n",
        "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "gray3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Initialize ORB detector\n",
        "orb = cv2.ORB_create()\n",
        "\n",
        "# Detect features in all images\n",
        "kp1, des1 = orb.detectAndCompute(gray1, None)\n",
        "kp2, des2 = orb.detectAndCompute(gray2, None)\n",
        "kp3, des3 = orb.detectAndCompute(gray3, None)\n",
        "\n",
        "# Create BFMatcher with cross-check\n",
        "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "\n",
        "# Match Image1 with Image2 and Image3\n",
        "matches_12 = bf.match(des1, des2)\n",
        "matches_13 = bf.match(des1, des3)\n",
        "\n",
        "# Create dictionaries for quick lookup\n",
        "match12_dict = {m.queryIdx: m for m in matches_12}\n",
        "match13_dict = {m.queryIdx: m for m in matches_13}\n",
        "\n",
        "# Find common features present in all matches\n",
        "common_features = []\n",
        "for q_idx in set(match12_dict.keys()) & set(match13_dict.keys()):\n",
        "    m12 = match12_dict[q_idx]\n",
        "    m13 = match13_dict[q_idx]\n",
        "    total_distance = m12.distance + m13.distance\n",
        "    common_features.append((\n",
        "        q_idx,        # Image1 keypoint index\n",
        "        m12.trainIdx,  # Image2 keypoint index\n",
        "        m13.trainIdx,  # Image3 keypoint index\n",
        "        total_distance\n",
        "    ))\n",
        "\n",
        "# Sort by match quality (lower distance = better)\n",
        "common_features.sort(key=lambda x: x[3])\n",
        "\n",
        "# Select top 1 common feature\n",
        "top_matches = common_features[:1]\n",
        "\n",
        "# Draw markers on all images\n",
        "colors = [(0, 0, 255), (0, 255, 0), (255, 0, 0)]  # Red, Green, Blue\n",
        "marker_type = cv2.MARKER_CROSS\n",
        "marker_size = 500\n",
        "thickness = 25\n",
        "\n",
        "for i, (q_idx, t12_idx, t13_idx, _) in enumerate(top_matches):\n",
        "    # Image 1\n",
        "    x1, y1 = map(int, kp1[q_idx].pt)\n",
        "    cv2.drawMarker(img1, (x1, y1), colors[i],\n",
        "                 marker_type, marker_size, thickness)\n",
        "\n",
        "    # Image 2\n",
        "    x2, y2 = map(int, kp2[t12_idx].pt)\n",
        "    cv2.drawMarker(img2, (x2, y2), colors[i],\n",
        "                 marker_type, marker_size, thickness)\n",
        "\n",
        "    # Image 3\n",
        "    x3, y3 = map(int, kp3[t13_idx].pt)\n",
        "    cv2.drawMarker(img3, (x3, y3), colors[i],\n",
        "                 marker_type, marker_size, thickness)\n",
        "\n",
        "# Save and display results\n",
        "cv2.imwrite('image1_3matches.jpg', img1)\n",
        "cv2.imwrite('image2_3matches.jpg', img2)\n",
        "cv2.imwrite('image3_3matches.jpg', img3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Elc9UVxmRMr",
        "outputId": "4a8af622-3ef8-48d0-b992-8e176450833f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([3610.0557, 1206.3379], dtype=float32), array([[3630.9575, 1884.1564]], dtype=float32), array([2974.0408, 1925.9602], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "camera_pts = np.float32([kp1[q_idx].pt, kp2[t12_idx].pt, kp3[t13_idx].pt])\n",
        "print(camera_pts)\n",
        "\n",
        "stage_pts = np.float32([[0,0], [0,1], [1,1]])\n",
        "print(camera_pts)\n",
        "\n",
        "# Compute affine transformation matrix\n",
        "T = cv2.getAffineTransform(stage_pts, camera_pts)\n",
        "\n",
        "# Print the transformation matrix\n",
        "print(\"Affine Transformation Matrix:\")\n",
        "print(T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCUimRcPnVAF",
        "outputId": "df59e7f8-014c-4f11-b46d-3ea2ba0de65a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3610.0557 1206.3379]\n",
            " [3630.9575 1884.1564]\n",
            " [2974.0408 1925.9602]]\n",
            "[[3610.0557 1206.3379]\n",
            " [3630.9575 1884.1564]\n",
            " [2974.0408 1925.9602]]\n",
            "Affine Transformation Matrix:\n",
            "[[-656.91674805   20.90185547 3610.05566406]\n",
            " [  41.80383301  677.81848145 1206.33789062]]\n"
          ]
        }
      ]
    }
  ]
}